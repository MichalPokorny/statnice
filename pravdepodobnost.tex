\documentclass[a4paper,10pt,titlepage]{article} \usepackage[utf8]{inputenc}
\usepackage{a4wide} \usepackage[czech]{babel}
\usepackage[small,compact]{titlesec}

\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\newtheorem{theorem}{Věta}
\newtheorem{define}{Definice}
\newtheorem*{notation}{Značení}
\newtheorem*{example}{Příklad}
\newtheorem*{remark}{Poznámka}

\begin{document} \pagestyle{empty}
\begin{center}
\textbf{Pravděpodobnost}
\end{center}

\begin{define}
(Pravděpodobnostní prostor)

$\Omega$ - množina možných výsledků, prvky jsou elementární jevy
$\mathbb{A} \subset \Omega$ je náhodný jev.
Chceme aby platily následující:
\begin{enumerate}
\item $\emptyset \in \mathbb{A}$,
\item $A \in \mathbb{A} \implies \Omega \setminus A \in \mathbb{A}$,
\item $A_1, \ldots A_n \in \mathbb{A} \implies \bigcup A_i \in \mathbb{A}$,
\item $P(\emptyset) = 0$,
\item $P(\Omega) = 1$,
\item $P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)$.
\end{enumerate}
\end{define}

\begin{define}
(Podmíněná pravděpodobnost)
\[
	P(A|B) = \frac{P(A \cap B)}{P(B)}
\]
\end{define}

\begin{define}
(Nezávislost náhodných jevů)
\[
P(A \cap B) = P(A) \cdot P(B)
\]
\end{define}

\begin{theorem}
(Věta o úplné pravděpodobnosti)
Předpoklady:
\[
	\bigcup B_i = \Omega \wedge B_i \cap B_j =\emptyset i\neq j
\]
Věta:
\[
P(A) = \sum P(A \cap B_i) = \sum P(A|B_i) \cdot B_i
\]
\end{theorem}

\begin{theorem}
(Bayesova věta)
Předpoklady:
\[
	\bigcup B_i = \Omega \wedge B_i \cap B_j =\emptyset i\neq j
\]
Věta:
\[
P(B_i|A) =\frac{P(B_i \cap A)}{P(A)} = \frac{P(A|B_i)\cdot P(B_i)}{\sum P(A|B_j) \cdot B_j}
\]
\end{theorem}

\begin{define}
(Náhodná veličina)

Funkce $f: \Omega \rightarrow \mathbb{R}$ taková, že ... TODO!!!
\end{define}

\begin{define}
(Spojitá náhodná veličina)

hustota - fce $f: \Omega \rightarrow \mathbb{R}$ ?? taková, že $\int_{\Omega} f dx = 1$.
\end{define}

\begin{define}
(Střední hodnota náhodné veličiny)

Diskrétní náhodná veličina:
\[
	\mathbb{E}[X] = \sum x_i \cdot P(X = x_i)
\]
Spojitá náhodná veličina: ($f$ je hustota)
\[
	\mathbb{E}[X] = \int x_i \cdot f(x_i) dx
\]
\end{define}

\begin{define}
(Moment)

$k$-tý moment náhodné veličiny je $\mathbb{E}[X^k]$.
$k$-tý centrální moment je $\mathbb{E}[(X-\mathbb{E}[X])^k]$.
\end{define}

Speciálně očekávaná hodnota je 1. moment a rozptyl je 2. centrální moment.

\begin{remark}
Vlastnosti střední hodnoty - pro $X,Y$ nezávislé:

\[
\mathbb{E}[\alpha \cdot X + Y] = \alpha \cdot \mathbb{E}[X] + \mathbb{E}[Y]
\]
\end{remark}

\begin{define}
(Rozptyl náhodné veličiny)
\[
	var(X) = \mathbb{E}[(X - \mathbb{E} (X))^2]
\]
\end{define}

\begin{define}
(Rozdělení náhodných veličin)

Rozdělení - $P(X = x)$ u diskrétní n.v., a hustota u spojité náhodné veličiny

Distribuční funkce - $P(X \leq x)$, počítá se jako integrál hustoty

"Inverze" distribuční funkce je kvantilová funkce: dostane pravděpodobnost $p$,
a vrátí hodnotu $x$, že $P(X\leq x)=p$.

\end{define}

\begin{define}
(Korelace, Kovariance)
\[
cov(X,Y) = \mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]
\]
\[
cor(X,Y) = \frac{cov(X,Y)}{\sqrt{var(X)var(Y)}}
\]
\end{define}

\section{Rozdělení náhodné veličiny}

\subsection{Diskrétní}

{\sc{Geometrické}}

$Ge(P)$ - házím, dokud nepadne

$P[X=k] = p^k \cdot (1-p)^{k-1}$

$\mathbb{E}[X] = \frac{1-p}{p}$

$var(x) = \frac{1-p}{p^2}$


{\sc{Binomické}}

$Bi(P)$ - střílí střelci na terč, rozdělení tref (resp. součet $n$ alternativních)

$P[X=k] = \binom{n}{k} p^k \cdot (1-p)^{n-k}$

$\mathbb{E}[X] = n\cdot p$

$var(x) = n \cdot p \cdot (1-p)$

{\sc{Poissonovo}}

$Po(P)$ 

$P[X=k] = \frac{\lambda ^k}{k!} \cdot e^{-\lambda}$

$\mathbb{E}[X] = \lambda$

$var(x) =\lambda$

\subsection{Spojité}

{\sc{Rovnoměrné}}

$f(x) = 1$ právě tehdy, když $x \in (0,1)$

$F(x) = x$ pro $x \in [0,1]$

$\mathbb{E}[X] = \frac{1}{2}$

$var(x) = \frac{1}{12}$ - ukáže se prostě dosazením do vzorce

\medskip

{\sc{Exponenciální}}

$f(x) = \lambda \cdot e^{-\lambda x}$

$\mathbb{E}[X] = \frac{1}{\lambda}$

$var(x) = \frac{1}{\lambda^2}$

{\sc{Normální rozdělení}}
$(N(\mu , \sigma ^2)$, standartně $N(0,1)$

$f(x) = \frac{1}{\sqrt{2 \pi \sigma ^2}} \cdot e^{-\frac{(x-\mu )^2}{2 \sigma ^2}}$

$\mathbb{E}[X] = \mu$

$var(x) = \sigma ^2$

Teorie odhadů.

Nezávislé náhodné veličiny $X_1\ldots X_N$ ze stejného rozdělení jsou náhodný výber.
Na základě výběru můžeme dělat \textbf{odhad} na nějakou vlastnost
$\theta\in\Theta$ toho rozdělení. Odhad je jakákoli funkce, která nezávisí na
odhadovaném parametru $\theta$ (skoro vždy závisí na náhodném výběru).

\begin{define}(Odhady)
Bodový odhad prostě tipne jedinou hodnotu $\theta$. Intervalové odhady řeknou 
(pro dopředu známou pravděpodobnost) nějaký interval, do kterého se s danou
pravdpodobností trefíme.
\end{define}

\begin{define}
Bodový odhad $T_n(X_1,\ldots X_N)$ je nestranný, když $\mathbb{E}[T_n(X_1,\ldots
N)]=\mathbb{E}_{\theta}T_n=\theta$ pro všechna $\theta\in\Theta$.
\end{define}

\begin{define}
Konzistentní bodové odhady: pro $N\rightarrow\infty$ a $\forall\varepsilon>0,
\theta\in\Theta$:
$P(|T_n-\Theta|>\varepsilon)\rightarrow 0$.
\end{define}

\begin{remark}
Průměr náh. výběru je dobrý odhad střední hodnoty.
\end{remark}

\begin{remark}
Výběrový rozptyl je dobrý odhad rozptylu.
\end{remark}

Metoda maximální věrohodnosti: $\theta$ odhadneme tak, aby naše $X_i$ byla
co nejvěrohodnější: $T_n=\arg\max_\theta \prod_{i} f(X_i,\theta)$.
Zlogaritmování zachová maximální věrohodnost: $T_n=\arg\max\sum\log
f(X_i,\theta)$.

Momentová metoda: odhadujeme $k$-tý moment jako $\frac{1}{n}\sum_{i=1}^n X_i^k$.
Řeší se jako soustava $k$ rovnic (resp. $k$ prvních momentů) pokud odhadujeme
$k$ parametrů.

\begin{define}(Intervaly spolehlivosti)

Interval spolehlivosti je nějaký interval, do kterého $\theta$ padne
s předem danou pravděpodobností $1-\alpha$. Speciálně se často volí
$\alpha=0.05$.
\end{define}

TODO: V papírech ze cvičení je obecná konstrukce intervalu spolehlivosti
přes pomocnou funkci $h$. AFAIK jsme odhadovali pouze střední hodnotu
(obecný parametr je velmi složitý)

TODO: intervaly spolehlivosti; konstrukce pro normalni rozdeleni

Testování hypotéz.

Hypotéza je výrok, jehož platnost chceme rozhodnout na základě dat.
Obvykle: nulová hypotéza $H_0$, alternativní hypotéza $H_1$. Pozor,
alternativa nemusí být negace nulové hypotézy.

Naše rozhodnutí můžou být A) zamítnout $H_0$, nebo B) nezamítnout $H_0$.
Nezamítnutí hypotézy neznamená její platnost - pouze říká, že nemáme dostatek
důkazů pro její zamítnutí (toto je klíčové!!!). Např. nám chybí dost dat.

Chyba 1. druhu je zamítnout $H_0$ když platí, 2. druh je nezamítnutí $H_0$
když $H_0$ neplatí. Chyba 1. druhu je vážnější -- je horší si myslet,
že $H_1$ platí, když neplatí, než si myslet, že $H_1$, když ve skutečnosti
$H_0$.

Hladina testu $\alpha$: pravděpodobnost chyby 1. druhu. \emph{Pozor}: hladinu
musíme nastavit ještě než začneme testovat! (to platí i pro p-value dále).
Síla testu $\beta$: chyba 2. druhu.

Příklad ze života (prof. Antoch) - Soudíme podezřelého. Platí presumpce neviny,
tzn. $H_0$: obžalovaný je nevinný. Hypotézu schválně nastavujeme takto, aby
chyba prvního druhu byla odsouzení nevinného (což je závažnější). Musíme mít
opravdu dost důkazů (nastavíme pomocí $\alpha$) abychom někoho poslali do vězení.

Statistika je libovolná funkce, která zobrazuje náhodný výběr do reálných čísel.
V praxi volíme statistiku tak, aby byla v případě neplatnosti hypotézy hodně malá
(tzn. ležela v tzv. kritickém oboru).

Testy v počítačích vracejí $p$-hodnoty: pravděpodobnost, že bychom dostali
výsledek, který stejně nebo víc svědčí \emph{proti} $H_0$, jestliže $H_0$ platí.
Konvence: $p$-hodnota $\leq\alpha\longrightarrow$ zamítáme $H_0$ a prokazujeme
$H_1$. Pokud není $\alpha$ nastavena předem (toto je velmi důležité), klesá
síla testu na polovinu.

TODO: T-test, $\chi^2$ test

Lineární model (regrese) je proložení naměřených bodů nějakou lineární funkcí
$\hat{f}$.
Uvažujeme pozorovaná data $Y_i$ a chceme najít model (přímku), která je
nejlépe vystihuje v závislosti na vysvětlující proměnné $X_i$.
Hledáme funkci ve tvaru $\hat{f}=\beta_0 + \beta_1X_i$. Dostáváme soustavu rovnic
$Y_i = \beta_0 + \beta_1X_i + u_i$. Použitím např. metody nejmenších čtverů získáme
koeficienty $\beta_i$, tedy celý model. Vysvětlujících proměnných může být celá řada
(např. pohlaví, výška, etc.) a nemusí být lineární (např. závislost na výšce může
být kvadratická) -- i v takovém případě hovoříme o lineárním modelu (resp. regresi).
Nelineární se regrese stává až když povolíme interakci mezi proměnnými (např součin).

TODO: Vzoreček na lineární regresi (je Hladíkově lingebře)

\end{document}
